{
  "category": "ai-prompt-engineering-advanced",
  "version": "1.0.0",
  "generatedBy": "Claude (Opus 4.5)",
  "description": "Advanced prompt engineering techniques",
  "skills": [
    {"id": "prm01", "type": "basic", "name": "Clear Instructions", "description": "Precise prompts", "pattern": "Be specific about desired output format and length", "example": "Respond in 3 bullet points"},
    {"id": "prm02", "type": "basic", "name": "Role Assignment", "description": "Give model a persona", "pattern": "You are an expert Python developer...", "example": "Context setting"},
    {"id": "prm03", "type": "basic", "name": "Output Format", "description": "Specify format", "pattern": "Respond in JSON format: { 'key': 'value' }", "example": "Structured output"},
    {"id": "prm04", "type": "technique", "name": "Few-Shot Learning", "description": "Provide examples", "pattern": "Example 1: Input -> Output\\nExample 2: Input -> Output\\nNow: Input -> ?", "example": "Pattern learning"},
    {"id": "prm05", "type": "technique", "name": "Zero-Shot", "description": "No examples needed", "pattern": "Translate this text to French: ...", "example": "Direct instruction"},
    {"id": "prm06", "type": "technique", "name": "Chain of Thought", "description": "Step-by-step reasoning", "pattern": "Let's think step by step...", "example": "Better for complex tasks"},
    {"id": "prm07", "type": "technique", "name": "Self-Consistency", "description": "Multiple reasoning paths", "pattern": "Generate 3 different solutions, then pick the best", "example": "Improved accuracy"},
    {"id": "prm08", "type": "technique", "name": "Tree of Thoughts", "description": "Branching reasoning", "pattern": "Consider multiple approaches, evaluate each", "example": "Complex problem solving"},
    {"id": "prm09", "type": "technique", "name": "ReAct Pattern", "description": "Reasoning + Acting", "pattern": "Thought: ... Action: ... Observation: ...", "example": "Tool-using agents"},
    {"id": "prm10", "type": "context", "name": "System Prompt", "description": "Set behavior context", "pattern": "System: You are a helpful assistant that...", "example": "Persistent context"},
    {"id": "prm11", "type": "context", "name": "Context Window", "description": "Token limits", "pattern": "Prioritize recent context, summarize old", "example": "Memory management"},
    {"id": "prm12", "type": "context", "name": "RAG Pattern", "description": "Retrieval-augmented", "pattern": "Search knowledge base, inject relevant docs in prompt", "example": "Factual accuracy"},
    {"id": "prm13", "type": "output", "name": "JSON Mode", "description": "Force JSON output", "pattern": "API: response_format: { type: 'json_object' }", "example": "Parseable output"},
    {"id": "prm14", "type": "output", "name": "Structured Extraction", "description": "Extract specific fields", "pattern": "Extract: name, date, amount from this text", "example": "Data extraction"},
    {"id": "prm15", "type": "output", "name": "Markdown Formatting", "description": "Rich text output", "pattern": "Format response with headers, lists, code blocks", "example": "Readable output"},
    {"id": "prm16", "type": "control", "name": "Temperature", "description": "Creativity control", "pattern": "0.0 = deterministic, 1.0 = creative", "example": "Adjust per use case"},
    {"id": "prm17", "type": "control", "name": "Max Tokens", "description": "Response length", "pattern": "Limit output length", "example": "Cost and speed"},
    {"id": "prm18", "type": "control", "name": "Stop Sequences", "description": "End generation", "pattern": "Stop when pattern appears", "example": "Controlled output"},
    {"id": "prm19", "type": "safety", "name": "Guardrails", "description": "Content filtering", "pattern": "Refuse harmful requests, stay on topic", "example": "Safety measures"},
    {"id": "prm20", "type": "safety", "name": "Prompt Injection Defense", "description": "Prevent attacks", "pattern": "Separate user input from instructions", "example": "Security measure"},
    {"id": "prm21", "type": "agent", "name": "Tool Calling", "description": "Function calling", "pattern": "Define available tools, let model choose", "example": "Agentic behavior"},
    {"id": "prm22", "type": "agent", "name": "Planning", "description": "Multi-step tasks", "pattern": "Create plan, execute steps, verify", "example": "Complex workflows"},
    {"id": "prm23", "type": "eval", "name": "Prompt Testing", "description": "Test prompts", "pattern": "Try multiple variations, measure quality", "example": "A/B testing prompts"},
    {"id": "prm24", "type": "eval", "name": "Evaluation Metrics", "description": "Measure quality", "pattern": "Accuracy, relevance, coherence, safety", "example": "Quality scoring"},
    {"id": "prm25", "type": "optimize", "name": "Prompt Compression", "description": "Reduce token usage", "pattern": "Remove unnecessary words, use abbreviations", "example": "Cost optimization"},
    {"id": "prm26", "type": "optimize", "name": "Caching", "description": "Cache common prompts", "pattern": "Cache system prompts, reuse contexts", "example": "Reduce latency"},
    {"id": "prm27", "type": "multilang", "name": "Multilingual Prompts", "description": "Non-English prompts", "pattern": "Prompt and respond in same language", "example": "Native language"},
    {"id": "prm28", "type": "code", "name": "Code Generation", "description": "Generate code", "pattern": "Specify language, include examples, request tests", "example": "Quality code output"},
    {"id": "prm29", "type": "debug", "name": "Debugging Prompts", "description": "Fix bad outputs", "pattern": "Add constraints, provide counter-examples", "example": "Iterative improvement"},
    {"id": "prm30", "type": "template", "name": "Prompt Templates", "description": "Reusable prompts", "pattern": "Variables in template: {{user_input}}", "example": "Parameterized prompts"}
  ]
}
