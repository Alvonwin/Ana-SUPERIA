{
  "category": "llm-development",
  "version": "1.0.0",
  "generatedBy": "Claude (Opus 4.5)",
  "skills": [
    {"id": "llm01", "type": "basics", "name": "LLM Basics", "description": "Large Language Models", "pattern": "Transformers, attention, tokens", "example": "AI text"},
    {"id": "llm02", "type": "api", "name": "API Integration", "description": "LLM APIs", "pattern": "OpenAI, Anthropic, Claude API", "example": "Cloud LLMs"},
    {"id": "llm03", "type": "prompt", "name": "Prompt Engineering", "description": "Effective prompts", "pattern": "System, user, assistant messages", "example": "Better outputs"},
    {"id": "llm04", "type": "rag", "name": "RAG", "description": "Retrieval Augmented", "pattern": "Embed, retrieve, generate", "example": "Knowledge base"},
    {"id": "llm05", "type": "embed", "name": "Embeddings", "description": "Vector representations", "pattern": "text-embedding-3, sentence-transformers", "example": "Semantic search"},
    {"id": "llm06", "type": "vector", "name": "Vector Databases", "description": "Embedding storage", "pattern": "Pinecone, Weaviate, Chroma", "example": "Similarity search"},
    {"id": "llm07", "type": "langchain", "name": "LangChain", "description": "LLM framework", "pattern": "Chains, agents, tools", "example": "Orchestration"},
    {"id": "llm08", "type": "llamaindex", "name": "LlamaIndex", "description": "Data framework", "pattern": "Indexes, retrievers, query engines", "example": "Data + LLM"},
    {"id": "llm09", "type": "finetune", "name": "Fine-Tuning", "description": "Custom training", "pattern": "LoRA, QLoRA, PEFT", "example": "Specialization"},
    {"id": "llm10", "type": "local", "name": "Local LLMs", "description": "Self-hosted models", "pattern": "Ollama, llama.cpp, vLLM", "example": "Privacy"},
    {"id": "llm11", "type": "agent", "name": "AI Agents", "description": "Autonomous AI", "pattern": "ReAct, tool use, planning", "example": "Task automation"},
    {"id": "llm12", "type": "function", "name": "Function Calling", "description": "Tool use", "pattern": "functions, tool_calls", "example": "Actions"},
    {"id": "llm13", "type": "stream", "name": "Streaming", "description": "Real-time output", "pattern": "SSE, stream=True", "example": "UX"},
    {"id": "llm14", "type": "memory", "name": "Conversation Memory", "description": "Context management", "pattern": "Buffer, summary, vector memory", "example": "State"},
    {"id": "llm15", "type": "chain", "name": "Chaining", "description": "Multi-step workflows", "pattern": "Sequential, parallel chains", "example": "Complex tasks"},
    {"id": "llm16", "type": "eval", "name": "Evaluation", "description": "Quality metrics", "pattern": "BLEU, ROUGE, human eval", "example": "Benchmarks"},
    {"id": "llm17", "type": "safety", "name": "Safety & Guardrails", "description": "Content filtering", "pattern": "Moderation, NeMo Guardrails", "example": "Protection"},
    {"id": "llm18", "type": "hallucination", "name": "Hallucination Mitigation", "description": "Accuracy", "pattern": "Grounding, citations, verification", "example": "Trust"},
    {"id": "llm19", "type": "context", "name": "Context Window", "description": "Token limits", "pattern": "Chunking, summarization", "example": "Long docs"},
    {"id": "llm20", "type": "cost", "name": "Cost Optimization", "description": "Token efficiency", "pattern": "Caching, model selection", "example": "Budget"},
    {"id": "llm21", "type": "multimodal", "name": "Multimodal LLMs", "description": "Vision + text", "pattern": "GPT-4V, Claude Vision", "example": "Images"},
    {"id": "llm22", "type": "structured", "name": "Structured Output", "description": "JSON mode", "pattern": "response_format, Instructor", "example": "Parsing"},
    {"id": "llm23", "type": "semantic", "name": "Semantic Search", "description": "Meaning-based search", "pattern": "Cosine similarity, hybrid search", "example": "Relevance"},
    {"id": "llm24", "type": "chunking", "name": "Document Chunking", "description": "Text splitting", "pattern": "Recursive, semantic chunking", "example": "Processing"},
    {"id": "llm25", "type": "routing", "name": "Query Routing", "description": "Model selection", "pattern": "Router chains, classifiers", "example": "Optimization"},
    {"id": "llm26", "type": "caching", "name": "Response Caching", "description": "Semantic cache", "pattern": "GPTCache, Redis", "example": "Performance"},
    {"id": "llm27", "type": "monitoring", "name": "LLM Monitoring", "description": "Observability", "pattern": "LangSmith, Helicone, Weights & Biases", "example": "Debugging"},
    {"id": "llm28", "type": "testing", "name": "LLM Testing", "description": "Quality assurance", "pattern": "Prompt testing, regression tests", "example": "Quality"},
    {"id": "llm29", "type": "deploy", "name": "LLM Deployment", "description": "Production", "pattern": "Serverless, GPU inference", "example": "Scaling"},
    {"id": "llm30", "type": "best", "name": "Best Practices", "description": "Guidelines", "pattern": "Prompt hygiene, error handling", "example": "Standards"}
  ]
}
