{
  "category": "generative-ai-models",
  "version": "1.0.0",
  "generatedBy": "Claude (Opus 4.5)",
  "description": "Generative AI Models and Architectures",
  "skills": [
    {"id": "gai01", "type": "basics", "name": "Generative AI Basics", "description": "Create new content", "pattern": "Learn distribution → Sample", "example": "Text, image, audio"},
    {"id": "gai02", "type": "llm", "name": "Large Language Models", "description": "Text generation", "pattern": "Transformer decoder", "example": "GPT, Claude"},
    {"id": "gai03", "type": "llm", "name": "Autoregressive Models", "description": "Token by token", "pattern": "P(xₜ|x₁...xₜ₋₁)", "example": "GPT generation"},
    {"id": "gai04", "type": "llm", "name": "Masked Language Models", "description": "Fill in blanks", "pattern": "Bidirectional context", "example": "BERT"},
    {"id": "gai05", "type": "diffusion", "name": "Diffusion Models", "description": "Denoise generation", "pattern": "Forward + reverse process", "example": "Stable Diffusion"},
    {"id": "gai06", "type": "diffusion", "name": "DDPM", "description": "Denoising diffusion", "pattern": "Probabilistic models", "example": "Original diffusion"},
    {"id": "gai07", "type": "diffusion", "name": "DDIM", "description": "Deterministic sampling", "pattern": "Faster inference", "example": "Fewer steps"},
    {"id": "gai08", "type": "diffusion", "name": "Latent Diffusion", "description": "Compressed space", "pattern": "VAE + diffusion", "example": "Stable Diffusion arch"},
    {"id": "gai09", "type": "diffusion", "name": "ControlNet", "description": "Conditional control", "pattern": "Add conditions", "example": "Pose, edge control"},
    {"id": "gai10", "type": "gan", "name": "GANs", "description": "Adversarial training", "pattern": "Generator vs discriminator", "example": "Image generation"},
    {"id": "gai11", "type": "gan", "name": "StyleGAN", "description": "Style-based generation", "pattern": "Mapping network", "example": "Face generation"},
    {"id": "gai12", "type": "gan", "name": "Progressive GAN", "description": "Gradual resolution", "pattern": "Low → high res", "example": "High-quality images"},
    {"id": "gai13", "type": "vae", "name": "VAE", "description": "Variational Autoencoder", "pattern": "Latent space", "example": "Learned compression"},
    {"id": "gai14", "type": "vae", "name": "Beta-VAE", "description": "Disentangled representations", "pattern": "Higher KL weight", "example": "Interpretable latents"},
    {"id": "gai15", "type": "vae", "name": "VQ-VAE", "description": "Discrete latents", "pattern": "Codebook vectors", "example": "Image tokens"},
    {"id": "gai16", "type": "flow", "name": "Flow Models", "description": "Invertible transformations", "pattern": "Exact likelihood", "example": "Normalizing flows"},
    {"id": "gai17", "type": "flow", "name": "RealNVP", "description": "Affine coupling", "pattern": "Tractable inverse", "example": "Image generation"},
    {"id": "gai18", "type": "multimodal", "name": "Text-to-Image", "description": "Image from text", "pattern": "CLIP + Diffusion", "example": "DALL-E, Midjourney"},
    {"id": "gai19", "type": "multimodal", "name": "Image-to-Image", "description": "Transform images", "pattern": "Condition on image", "example": "Inpainting, style"},
    {"id": "gai20", "type": "multimodal", "name": "Text-to-Video", "description": "Video from text", "pattern": "Temporal diffusion", "example": "Sora, Runway"},
    {"id": "gai21", "type": "multimodal", "name": "Text-to-Audio", "description": "Audio generation", "pattern": "Audio diffusion", "example": "Music generation"},
    {"id": "gai22", "type": "multimodal", "name": "Text-to-3D", "description": "3D generation", "pattern": "NeRF + diffusion", "example": "DreamFusion"},
    {"id": "gai23", "type": "architecture", "name": "U-Net", "description": "Image backbone", "pattern": "Encoder-decoder + skip", "example": "Diffusion backbone"},
    {"id": "gai24", "type": "architecture", "name": "DiT", "description": "Diffusion Transformer", "pattern": "Transformer backbone", "example": "Modern diffusion"},
    {"id": "gai25", "type": "training", "name": "Classifier-Free Guidance", "description": "Conditional generation", "pattern": "Conditional - unconditional", "example": "Better quality"},
    {"id": "gai26", "type": "training", "name": "CLIP Guidance", "description": "Text-image alignment", "pattern": "CLIP loss guidance", "example": "Text conditioning"},
    {"id": "gai27", "type": "inference", "name": "Sampling Schedulers", "description": "Noise schedules", "pattern": "PNDM, Euler, DPM++", "example": "Quality vs speed"},
    {"id": "gai28", "type": "inference", "name": "Negative Prompts", "description": "What to avoid", "pattern": "Subtract guidance", "example": "Quality improvement"},
    {"id": "gai29", "type": "tools", "name": "ComfyUI", "description": "Node-based UI", "pattern": "Visual workflows", "example": "Flexible generation"},
    {"id": "gai30", "type": "tools", "name": "Automatic1111", "description": "Web UI", "pattern": "Feature-rich interface", "example": "Popular SD UI"}
  ]
}
