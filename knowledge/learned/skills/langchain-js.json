{
  "category": "langchain-js",
  "version": "1.0.0",
  "generatedBy": "Claude (Opus 4.5)",
  "skills": [
    {"id": "lc01", "type": "basics", "name": "LangChain.js Basics", "description": "LLM framework", "pattern": "Chains, agents, memory, tools for AI apps", "example": "AI framework"},
    {"id": "lc02", "type": "install", "name": "Installation", "description": "Setup LangChain", "pattern": "npm install langchain @langchain/openai", "example": "Getting started"},
    {"id": "lc03", "type": "llm", "name": "LLM Models", "description": "Model wrappers", "pattern": "ChatOpenAI, ChatAnthropic, ChatOllama", "example": "Model setup"},
    {"id": "lc04", "type": "invoke", "name": "Model Invocation", "description": "Call models", "pattern": "model.invoke([messages]), await model.call()", "example": "Calling LLM"},
    {"id": "lc05", "type": "messages", "name": "Message Types", "description": "Chat messages", "pattern": "HumanMessage, AIMessage, SystemMessage", "example": "Message format"},
    {"id": "lc06", "type": "prompts", "name": "Prompt Templates", "description": "Template prompts", "pattern": "PromptTemplate.fromTemplate('Hello {name}')", "example": "Prompts"},
    {"id": "lc07", "type": "chat", "name": "Chat Prompts", "description": "Chat templates", "pattern": "ChatPromptTemplate.fromMessages([...])", "example": "Chat prompts"},
    {"id": "lc08", "type": "chains", "name": "Chains", "description": "Sequence operations", "pattern": "prompt.pipe(model).pipe(outputParser)", "example": "Chains"},
    {"id": "lc09", "type": "lcel", "name": "LCEL", "description": "Expression language", "pattern": "Runnable.pipe(), compose chains", "example": "Composition"},
    {"id": "lc10", "type": "output", "name": "Output Parsers", "description": "Parse responses", "pattern": "StringOutputParser, StructuredOutputParser", "example": "Parsing"},
    {"id": "lc11", "type": "streaming", "name": "Streaming", "description": "Stream responses", "pattern": "model.stream(), for await (const chunk of...)", "example": "Streaming"},
    {"id": "lc12", "type": "memory", "name": "Memory", "description": "Conversation memory", "pattern": "BufferMemory, ConversationSummaryMemory", "example": "Context"},
    {"id": "lc13", "type": "tools", "name": "Tools", "description": "LLM tools", "pattern": "DynamicTool, StructuredTool, @tool decorator", "example": "Tool creation"},
    {"id": "lc14", "type": "agents", "name": "Agents", "description": "Autonomous agents", "pattern": "createOpenAIFunctionsAgent, AgentExecutor", "example": "Agents"},
    {"id": "lc15", "type": "rag", "name": "RAG", "description": "Retrieval-augmented", "pattern": "Retriever + LLM, RetrievalQAChain", "example": "RAG pattern"},
    {"id": "lc16", "type": "vectorstore", "name": "Vector Stores", "description": "Vector databases", "pattern": "Chroma, Pinecone, Faiss, MemoryVectorStore", "example": "Vector DB"},
    {"id": "lc17", "type": "embeddings", "name": "Embeddings", "description": "Text embeddings", "pattern": "OpenAIEmbeddings, embedDocuments()", "example": "Embeddings"},
    {"id": "lc18", "type": "documents", "name": "Document Loaders", "description": "Load documents", "pattern": "PDFLoader, TextLoader, WebLoader", "example": "Doc loading"},
    {"id": "lc19", "type": "splitters", "name": "Text Splitters", "description": "Chunk text", "pattern": "RecursiveCharacterTextSplitter, chunkSize", "example": "Splitting"},
    {"id": "lc20", "type": "retrievers", "name": "Retrievers", "description": "Document retrieval", "pattern": "vectorStore.asRetriever(), similarity search", "example": "Retrieval"},
    {"id": "lc21", "type": "callbacks", "name": "Callbacks", "description": "Event handlers", "pattern": "callbacks: [handler], onLLMStart, onLLMEnd", "example": "Events"},
    {"id": "lc22", "type": "langgraph", "name": "LangGraph", "description": "State graphs", "pattern": "StateGraph, nodes, edges, conditional edges", "example": "Workflows"},
    {"id": "lc23", "type": "langsmith", "name": "LangSmith", "description": "Tracing/debugging", "pattern": "LANGCHAIN_TRACING_V2=true", "example": "Debugging"},
    {"id": "lc24", "type": "hub", "name": "LangChain Hub", "description": "Prompt hub", "pattern": "pull('hwchase17/openai-tools-agent')", "example": "Prompt sharing"},
    {"id": "lc25", "type": "functions", "name": "Function Calling", "description": "Tool binding", "pattern": "model.bindTools([tool])", "example": "Functions"},
    {"id": "lc26", "type": "structured", "name": "Structured Output", "description": "Schema output", "pattern": "model.withStructuredOutput(schema)", "example": "Structured"},
    {"id": "lc27", "type": "multi", "name": "Multi-Modal", "description": "Images + text", "pattern": "HumanMessage with image content", "example": "Vision"},
    {"id": "lc28", "type": "fallbacks", "name": "Fallbacks", "description": "Error handling", "pattern": "model.withFallbacks([backupModel])", "example": "Resilience"},
    {"id": "lc29", "type": "batch", "name": "Batch Processing", "description": "Batch calls", "pattern": "chain.batch([input1, input2])", "example": "Batch"},
    {"id": "lc30", "type": "best", "name": "Best Practices", "description": "LangChain guidelines", "pattern": "LCEL, streaming, callbacks, LangSmith", "example": "Standards"}
  ]
}
