{
  "category": "computer-vision-cv",
  "version": "1.0.0",
  "generatedBy": "Claude (Opus 4.5)",
  "skills": [
    {"id": "cv01", "type": "basics", "name": "CV Basics", "description": "Computer Vision fundamentals", "pattern": "Image understanding, processing", "example": "Visual AI"},
    {"id": "cv02", "type": "image", "name": "Image Basics", "description": "Digital images", "pattern": "Pixels, channels, resolution", "example": "Image data"},
    {"id": "cv03", "type": "preprocessing", "name": "Image Preprocessing", "description": "Prepare images", "pattern": "Resize, normalize, augment", "example": "Data prep"},
    {"id": "cv04", "type": "filter", "name": "Image Filtering", "description": "Convolution", "pattern": "Blur, sharpen, edge detection", "example": "Enhancement"},
    {"id": "cv05", "type": "edge", "name": "Edge Detection", "description": "Find edges", "pattern": "Canny, Sobel, Laplacian", "example": "Feature detection"},
    {"id": "cv06", "type": "segmentation", "name": "Image Segmentation", "description": "Divide image", "pattern": "Semantic, instance segmentation", "example": "Object boundaries"},
    {"id": "cv07", "type": "classification", "name": "Image Classification", "description": "Categorize images", "pattern": "CNN, ResNet, EfficientNet", "example": "What is it?"},
    {"id": "cv08", "type": "detection", "name": "Object Detection", "description": "Find objects", "pattern": "YOLO, SSD, Faster R-CNN", "example": "Where is it?"},
    {"id": "cv09", "type": "face", "name": "Face Detection", "description": "Find faces", "pattern": "Haar cascades, MTCNN", "example": "Face location"},
    {"id": "cv10", "type": "recognition", "name": "Face Recognition", "description": "Identify people", "pattern": "FaceNet, ArcFace, embeddings", "example": "Who is it?"},
    {"id": "cv11", "type": "ocr", "name": "OCR", "description": "Text recognition", "pattern": "Tesseract, EasyOCR, PaddleOCR", "example": "Extract text"},
    {"id": "cv12", "type": "pose", "name": "Pose Estimation", "description": "Body keypoints", "pattern": "OpenPose, MediaPipe, skeleton", "example": "Body tracking"},
    {"id": "cv13", "type": "tracking", "name": "Object Tracking", "description": "Follow objects", "pattern": "SORT, DeepSORT, ByteTrack", "example": "Video tracking"},
    {"id": "cv14", "type": "depth", "name": "Depth Estimation", "description": "3D from 2D", "pattern": "Monocular depth, stereo", "example": "Distance estimation"},
    {"id": "cv15", "type": "opencv", "name": "OpenCV", "description": "CV library", "pattern": "cv2, Mat, VideoCapture", "example": "Classic CV"},
    {"id": "cv16", "type": "pytorch", "name": "PyTorch Vision", "description": "DL for CV", "pattern": "torchvision, transforms", "example": "Deep CV"},
    {"id": "cv17", "type": "augmentation", "name": "Data Augmentation", "description": "Increase data", "pattern": "Albumentations, flip, rotate", "example": "More training data"},
    {"id": "cv18", "type": "transfer", "name": "Transfer Learning", "description": "Pretrained models", "pattern": "ImageNet weights, fine-tune", "example": "Less data needed"},
    {"id": "cv19", "type": "cnn", "name": "CNN Architectures", "description": "Network designs", "pattern": "VGG, ResNet, Inception", "example": "Model choice"},
    {"id": "cv20", "type": "attention", "name": "Vision Transformers", "description": "ViT", "pattern": "Patch embeddings, attention", "example": "Modern CV"},
    {"id": "cv21", "type": "gan", "name": "Image Generation", "description": "Create images", "pattern": "GAN, StyleGAN, Diffusion", "example": "Synthetic images"},
    {"id": "cv22", "type": "sr", "name": "Super Resolution", "description": "Enhance resolution", "pattern": "ESRGAN, Real-ESRGAN", "example": "Upscaling"},
    {"id": "cv23", "type": "style", "name": "Style Transfer", "description": "Artistic styles", "pattern": "Neural style transfer", "example": "Art effects"},
    {"id": "cv24", "type": "3d", "name": "3D Vision", "description": "3D understanding", "pattern": "Point clouds, NeRF", "example": "Spatial AI"},
    {"id": "cv25", "type": "video", "name": "Video Analysis", "description": "Video processing", "pattern": "Frame extraction, temporal", "example": "Motion analysis"},
    {"id": "cv26", "type": "action", "name": "Action Recognition", "description": "Classify actions", "pattern": "Temporal models, I3D", "example": "What happening?"},
    {"id": "cv27", "type": "annotation", "name": "Annotation", "description": "Label data", "pattern": "COCO, YOLO format, LabelImg", "example": "Training data"},
    {"id": "cv28", "type": "deployment", "name": "CV Deployment", "description": "Production", "pattern": "ONNX, TensorRT, OpenVINO", "example": "Inference"},
    {"id": "cv29", "type": "edge", "name": "Edge CV", "description": "On-device", "pattern": "TFLite, CoreML, Jetson", "example": "Mobile/IoT"},
    {"id": "cv30", "type": "multimodal", "name": "Multimodal", "description": "Vision + Language", "pattern": "CLIP, BLIP, GPT-4V", "example": "VLM"}
  ]
}
