{
  "category": "kafka-streaming",
  "version": "1.0.0",
  "generatedBy": "Claude (Opus 4.5)",
  "skills": [
    {"id": "kfk01", "type": "basics", "name": "Kafka Basics", "description": "Event streaming platform", "pattern": "Topics, partitions, brokers", "example": "Message queue"},
    {"id": "kfk02", "type": "producer", "name": "Producers", "description": "Send messages", "pattern": "KafkaProducer, send(), acks", "example": "Publish events"},
    {"id": "kfk03", "type": "consumer", "name": "Consumers", "description": "Receive messages", "pattern": "KafkaConsumer, poll(), subscribe", "example": "Consume events"},
    {"id": "kfk04", "type": "topic", "name": "Topics", "description": "Message categories", "pattern": "create topic, partitions, replication", "example": "Data streams"},
    {"id": "kfk05", "type": "partition", "name": "Partitioning", "description": "Data distribution", "pattern": "Partition key, ordering", "example": "Parallelism"},
    {"id": "kfk06", "type": "consumergroup", "name": "Consumer Groups", "description": "Parallel consumption", "pattern": "group.id, rebalancing", "example": "Scaling"},
    {"id": "kfk07", "type": "offset", "name": "Offset Management", "description": "Message tracking", "pattern": "commit, seek, auto.offset.reset", "example": "Position tracking"},
    {"id": "kfk08", "type": "serialization", "name": "Serialization", "description": "Message format", "pattern": "Avro, JSON, Protobuf serializers", "example": "Data encoding"},
    {"id": "kfk09", "type": "schema", "name": "Schema Registry", "description": "Schema management", "pattern": "Confluent Schema Registry", "example": "Data contracts"},
    {"id": "kfk10", "type": "streams", "name": "Kafka Streams", "description": "Stream processing", "pattern": "KStream, KTable, joins", "example": "Real-time processing"},
    {"id": "kfk11", "type": "connect", "name": "Kafka Connect", "description": "Data integration", "pattern": "Source, sink connectors", "example": "ETL"},
    {"id": "kfk12", "type": "ksql", "name": "ksqlDB", "description": "SQL on streams", "pattern": "CREATE STREAM, queries", "example": "Stream SQL"},
    {"id": "kfk13", "type": "transactions", "name": "Transactions", "description": "Exactly-once", "pattern": "transactional.id, EOS", "example": "Reliability"},
    {"id": "kfk14", "type": "retention", "name": "Retention", "description": "Message storage", "pattern": "retention.ms, log compaction", "example": "Data lifecycle"},
    {"id": "kfk15", "type": "compaction", "name": "Log Compaction", "description": "Key-based retention", "pattern": "cleanup.policy=compact", "example": "State storage"},
    {"id": "kfk16", "type": "replication", "name": "Replication", "description": "Fault tolerance", "pattern": "replication.factor, ISR", "example": "HA"},
    {"id": "kfk17", "type": "cluster", "name": "Cluster Management", "description": "Multi-broker", "pattern": "ZooKeeper, KRaft mode", "example": "Operations"},
    {"id": "kfk18", "type": "security", "name": "Security", "description": "Access control", "pattern": "SSL, SASL, ACLs", "example": "Protection"},
    {"id": "kfk19", "type": "monitoring", "name": "Monitoring", "description": "Observability", "pattern": "JMX metrics, Kafka Manager", "example": "Diagnostics"},
    {"id": "kfk20", "type": "performance", "name": "Performance Tuning", "description": "Optimization", "pattern": "batch.size, linger.ms, compression", "example": "Throughput"},
    {"id": "kfk21", "type": "mirrormaker", "name": "MirrorMaker", "description": "Cross-cluster replication", "pattern": "MM2, geo-replication", "example": "Multi-DC"},
    {"id": "kfk22", "type": "testing", "name": "Testing", "description": "Kafka tests", "pattern": "EmbeddedKafka, Testcontainers", "example": "Quality"},
    {"id": "kfk23", "type": "java", "name": "Java Client", "description": "Java API", "pattern": "kafka-clients dependency", "example": "Java apps"},
    {"id": "kfk24", "type": "python", "name": "Python Client", "description": "Python API", "pattern": "confluent-kafka, kafka-python", "example": "Python apps"},
    {"id": "kfk25", "type": "nodejs", "name": "Node.js Client", "description": "Node API", "pattern": "kafkajs, node-rdkafka", "example": "Node apps"},
    {"id": "kfk26", "type": "windowing", "name": "Windowing", "description": "Time windows", "pattern": "Tumbling, hopping, session windows", "example": "Aggregations"},
    {"id": "kfk27", "type": "statestore", "name": "State Stores", "description": "Local state", "pattern": "RocksDB, queryable state", "example": "Stateful processing"},
    {"id": "kfk28", "type": "errorhandling", "name": "Error Handling", "description": "Dead letter queues", "pattern": "DLQ, retry topics", "example": "Fault tolerance"},
    {"id": "kfk29", "type": "cloud", "name": "Managed Kafka", "description": "Cloud services", "pattern": "Confluent Cloud, AWS MSK", "example": "SaaS"},
    {"id": "kfk30", "type": "best", "name": "Best Practices", "description": "Guidelines", "pattern": "Topic design, consumer patterns", "example": "Standards"}
  ]
}
