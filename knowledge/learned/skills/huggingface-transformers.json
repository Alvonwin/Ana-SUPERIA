{
  "category": "huggingface-transformers",
  "version": "1.0.0",
  "generatedBy": "Claude (Opus 4.5)",
  "description": "Hugging Face Transformers library patterns",
  "skills": [
    {"id": "hf01", "type": "setup", "name": "Install Transformers", "description": "Add library", "pattern": "pip install transformers torch", "example": "Python library"},
    {"id": "hf02", "type": "setup", "name": "Install JS", "description": "JavaScript SDK", "pattern": "npm install @huggingface/transformers", "example": "Browser/Node.js"},
    {"id": "hf03", "type": "pipeline", "name": "Pipeline API", "description": "Quick inference", "pattern": "from transformers import pipeline; classifier = pipeline('sentiment-analysis')", "example": "High-level API"},
    {"id": "hf04", "type": "pipeline", "name": "Text Classification", "description": "Classify text", "pattern": "classifier('I love this product!')", "example": "Sentiment analysis"},
    {"id": "hf05", "type": "pipeline", "name": "Text Generation", "description": "Generate text", "pattern": "generator = pipeline('text-generation', model='gpt2'); generator('Once upon a time')", "example": "Autoregressive"},
    {"id": "hf06", "type": "pipeline", "name": "Question Answering", "description": "QA task", "pattern": "qa = pipeline('question-answering'); qa(question='What is AI?', context='...')", "example": "Extract answers"},
    {"id": "hf07", "type": "pipeline", "name": "Summarization", "description": "Summarize text", "pattern": "summarizer = pipeline('summarization'); summarizer(long_text)", "example": "Condense text"},
    {"id": "hf08", "type": "pipeline", "name": "Translation", "description": "Translate text", "pattern": "translator = pipeline('translation_en_to_fr'); translator('Hello world')", "example": "Language translation"},
    {"id": "hf09", "type": "pipeline", "name": "Named Entity Recognition", "description": "NER task", "pattern": "ner = pipeline('ner'); ner('John works at Google in New York')", "example": "Entity extraction"},
    {"id": "hf10", "type": "pipeline", "name": "Zero-shot Classification", "description": "No training", "pattern": "classifier = pipeline('zero-shot-classification'); classifier(text, candidate_labels=['sports', 'politics'])", "example": "Flexible labels"},
    {"id": "hf11", "type": "pipeline", "name": "Image Classification", "description": "Classify images", "pattern": "classifier = pipeline('image-classification'); classifier('image.jpg')", "example": "Vision task"},
    {"id": "hf12", "type": "pipeline", "name": "Object Detection", "description": "Detect objects", "pattern": "detector = pipeline('object-detection'); detector('image.jpg')", "example": "Bounding boxes"},
    {"id": "hf13", "type": "pipeline", "name": "Speech Recognition", "description": "ASR", "pattern": "transcriber = pipeline('automatic-speech-recognition'); transcriber('audio.wav')", "example": "Whisper models"},
    {"id": "hf14", "type": "model", "name": "Load Model", "description": "Load pretrained", "pattern": "from transformers import AutoModel; model = AutoModel.from_pretrained('bert-base-uncased')", "example": "Auto classes"},
    {"id": "hf15", "type": "model", "name": "Load Tokenizer", "description": "Tokenize text", "pattern": "from transformers import AutoTokenizer; tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')", "example": "Text to tokens"},
    {"id": "hf16", "type": "model", "name": "Tokenize", "description": "Encode text", "pattern": "tokens = tokenizer('Hello world', return_tensors='pt')", "example": "Input preparation"},
    {"id": "hf17", "type": "model", "name": "Inference", "description": "Run model", "pattern": "outputs = model(**tokens)", "example": "Forward pass"},
    {"id": "hf18", "type": "model", "name": "Decode Output", "description": "Tokens to text", "pattern": "tokenizer.decode(output_ids[0], skip_special_tokens=True)", "example": "Generate text"},
    {"id": "hf19", "type": "train", "name": "Trainer API", "description": "Fine-tuning", "pattern": "from transformers import Trainer, TrainingArguments", "example": "Training loop"},
    {"id": "hf20", "type": "train", "name": "Training Arguments", "description": "Config training", "pattern": "TrainingArguments(output_dir='./results', num_train_epochs=3, per_device_train_batch_size=16)", "example": "Hyperparameters"},
    {"id": "hf21", "type": "train", "name": "Train Model", "description": "Start training", "pattern": "trainer = Trainer(model=model, args=args, train_dataset=dataset); trainer.train()", "example": "Execute training"},
    {"id": "hf22", "type": "dataset", "name": "Load Dataset", "description": "HF Datasets", "pattern": "from datasets import load_dataset; dataset = load_dataset('imdb')", "example": "Dataset hub"},
    {"id": "hf23", "type": "dataset", "name": "Process Dataset", "description": "Transform data", "pattern": "dataset.map(tokenize_function, batched=True)", "example": "Preprocessing"},
    {"id": "hf24", "type": "hub", "name": "Hub Login", "description": "Authenticate", "pattern": "from huggingface_hub import login; login(token='hf_...')", "example": "Access private"},
    {"id": "hf25", "type": "hub", "name": "Push to Hub", "description": "Share model", "pattern": "model.push_to_hub('username/model-name')", "example": "Publish model"},
    {"id": "hf26", "type": "hub", "name": "Download Model", "description": "Get model", "pattern": "from huggingface_hub import hf_hub_download", "example": "Download files"},
    {"id": "hf27", "type": "optimize", "name": "Quantization", "description": "Reduce size", "pattern": "from transformers import BitsAndBytesConfig; 4-bit or 8-bit", "example": "Smaller models"},
    {"id": "hf28", "type": "optimize", "name": "ONNX Export", "description": "Export model", "pattern": "optimum library for ONNX export", "example": "Cross-platform"},
    {"id": "hf29", "type": "inference", "name": "Inference API", "description": "Hosted inference", "pattern": "requests.post('https://api-inference.huggingface.co/models/...', headers, json)", "example": "Serverless"},
    {"id": "hf30", "type": "space", "name": "Spaces", "description": "Deploy demo", "pattern": "Gradio or Streamlit app on HF Spaces", "example": "Interactive demo"}
  ]
}
