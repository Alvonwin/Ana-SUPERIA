{
  "category": "observability-monitoring",
  "version": "1.0.0",
  "generatedBy": "Claude Opus 4.5 - Module de référence pour Ana SUPERIA",
  "skills": [
    {"id": "obs01", "type": "metrics", "name": "Prometheus Metrics", "description": "Expose application metrics", "pattern": "const { Counter, Histogram, Gauge, register } = require('prom-client');\n\nconst httpRequests = new Counter({\n  name: 'http_requests_total',\n  help: 'Total HTTP requests',\n  labelNames: ['method', 'path', 'status']\n});\n\napp.use((req, res, next) => {\n  res.on('finish', () => httpRequests.inc({ method: req.method, path: req.path, status: res.statusCode }));\n  next();\n});\n\napp.get('/metrics', async (req, res) => res.send(await register.metrics()));", "example": "Counter, Histogram, Gauge metrics"},
    {"id": "obs02", "type": "metrics", "name": "RED Metrics", "description": "Rate, Errors, Duration for services", "pattern": "// Rate: requests per second\nconst requestRate = new Counter({ name: 'http_requests_total' });\n\n// Errors: error count/rate\nconst errorRate = new Counter({ name: 'http_errors_total' });\n\n// Duration: latency histogram\nconst duration = new Histogram({\n  name: 'http_request_duration_seconds',\n  buckets: [0.01, 0.05, 0.1, 0.5, 1, 5]\n});", "example": "Essential service health metrics"},
    {"id": "obs03", "type": "metrics", "name": "USE Metrics", "description": "Utilization, Saturation, Errors for resources", "pattern": "// Utilization: % time resource is busy\nconst cpuUtilization = new Gauge({ name: 'cpu_utilization_percent' });\n\n// Saturation: queue length\nconst connectionPoolQueue = new Gauge({ name: 'db_pool_waiting_connections' });\n\n// Errors: error count\nconst diskErrors = new Counter({ name: 'disk_io_errors_total' });", "example": "For infrastructure components"},
    {"id": "obs04", "type": "logging", "name": "Structured Logging", "description": "JSON-formatted log output", "pattern": "const logger = pino({\n  level: process.env.LOG_LEVEL || 'info',\n  formatters: {\n    level: (label) => ({ level: label })\n  },\n  base: { service: 'user-service', version: '1.0.0' }\n});\n\nlogger.info({ userId: '123', action: 'login' }, 'User logged in');\n// Output: {\"level\":\"info\",\"service\":\"user-service\",\"userId\":\"123\",\"action\":\"login\",\"msg\":\"User logged in\"}", "example": "Machine-parseable logs"},
    {"id": "obs05", "type": "logging", "name": "Log Correlation", "description": "Correlate logs with request IDs", "pattern": "const asyncLocalStorage = new AsyncLocalStorage();\n\napp.use((req, res, next) => {\n  const requestId = req.headers['x-request-id'] || crypto.randomUUID();\n  asyncLocalStorage.run({ requestId }, () => next());\n});\n\nfunction log(message, data = {}) {\n  const store = asyncLocalStorage.getStore();\n  logger.info({ ...data, requestId: store?.requestId }, message);\n}", "example": "Trace requests across logs"},
    {"id": "obs06", "type": "tracing", "name": "OpenTelemetry Setup", "description": "Initialize distributed tracing", "pattern": "const { NodeSDK } = require('@opentelemetry/sdk-node');\nconst { JaegerExporter } = require('@opentelemetry/exporter-jaeger');\n\nconst sdk = new NodeSDK({\n  traceExporter: new JaegerExporter({ endpoint: 'http://jaeger:14268/api/traces' }),\n  instrumentations: [\n    getNodeAutoInstrumentations({\n      '@opentelemetry/instrumentation-http': { enabled: true },\n      '@opentelemetry/instrumentation-express': { enabled: true }\n    })\n  ]\n});\nsdk.start();", "example": "Auto-instrumentation for HTTP, DB"},
    {"id": "obs07", "type": "tracing", "name": "Custom Spans", "description": "Create spans for custom operations", "pattern": "const tracer = trace.getTracer('my-service');\n\nasync function processOrder(order) {\n  return tracer.startActiveSpan('processOrder', async (span) => {\n    span.setAttribute('order.id', order.id);\n    span.setAttribute('order.total', order.total);\n    \n    try {\n      await validateOrder(order);\n      await chargePayment(order);\n      span.setStatus({ code: SpanStatusCode.OK });\n    } catch (error) {\n      span.setStatus({ code: SpanStatusCode.ERROR, message: error.message });\n      span.recordException(error);\n      throw error;\n    } finally {\n      span.end();\n    }\n  });\n}", "example": "Add spans for business logic"},
    {"id": "obs08", "type": "alerting", "name": "Prometheus Alerting", "description": "Define alert rules", "pattern": "# prometheus/rules.yml\ngroups:\n- name: api-alerts\n  rules:\n  - alert: HighErrorRate\n    expr: rate(http_errors_total[5m]) / rate(http_requests_total[5m]) > 0.05\n    for: 5m\n    labels:\n      severity: critical\n    annotations:\n      summary: High error rate detected\n      description: Error rate is {{ $value | humanizePercentage }}", "example": "Alert on error rate, latency"},
    {"id": "obs09", "type": "alerting", "name": "PagerDuty Integration", "description": "Route alerts to on-call", "pattern": "# alertmanager.yml\nreceivers:\n- name: pagerduty-critical\n  pagerduty_configs:\n  - service_key: 'YOUR_PAGERDUTY_KEY'\n    severity: critical\n\nroute:\n  receiver: default\n  routes:\n  - match:\n      severity: critical\n    receiver: pagerduty-critical", "example": "Escalate critical alerts"},
    {"id": "obs10", "type": "dashboards", "name": "Grafana Dashboards", "description": "Create monitoring dashboards", "pattern": "{\n  \"panels\": [{\n    \"title\": \"Request Rate\",\n    \"type\": \"graph\",\n    \"targets\": [{\n      \"expr\": \"rate(http_requests_total[5m])\",\n      \"legendFormat\": \"{{method}} {{path}}\"\n    }]\n  }, {\n    \"title\": \"P99 Latency\",\n    \"type\": \"stat\",\n    \"targets\": [{\n      \"expr\": \"histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))\"\n    }]\n  }]\n}", "example": "Visualize metrics in Grafana"},
    {"id": "obs11", "type": "logging", "name": "ELK Stack", "description": "Elasticsearch, Logstash, Kibana", "pattern": "# logstash.conf\ninput {\n  beats { port => 5044 }\n}\nfilter {\n  json { source => \"message\" }\n  date { match => [\"timestamp\", \"ISO8601\"] }\n}\noutput {\n  elasticsearch {\n    hosts => [\"elasticsearch:9200\"]\n    index => \"logs-%{+YYYY.MM.dd}\"\n  }\n}", "example": "Centralized log aggregation"},
    {"id": "obs12", "type": "apm", "name": "Application Performance Monitoring", "description": "Full APM with Datadog/New Relic", "pattern": "// Datadog APM\nconst tracer = require('dd-trace').init({\n  service: 'my-service',\n  env: process.env.NODE_ENV,\n  version: '1.0.0',\n  logInjection: true,\n  runtimeMetrics: true,\n  profiling: true\n});", "example": "Traces, metrics, logs in one platform"},
    {"id": "obs13", "type": "health", "name": "Health Check Endpoints", "description": "Comprehensive health checks", "pattern": "app.get('/health', async (req, res) => {\n  const checks = {\n    database: await checkDatabase(),\n    redis: await checkRedis(),\n    externalApi: await checkExternalApi()\n  };\n  const allHealthy = Object.values(checks).every(c => c.status === 'healthy');\n  res.status(allHealthy ? 200 : 503).json({\n    status: allHealthy ? 'healthy' : 'unhealthy',\n    checks,\n    timestamp: new Date().toISOString()\n  });\n});", "example": "Check all dependencies"},
    {"id": "obs14", "type": "profiling", "name": "CPU Profiling", "description": "Profile CPU usage", "pattern": "const v8Profiler = require('v8-profiler-next');\n\napp.get('/debug/profile', async (req, res) => {\n  v8Profiler.startProfiling('CPU', true);\n  setTimeout(() => {\n    const profile = v8Profiler.stopProfiling();\n    profile.export((error, result) => {\n      res.setHeader('Content-Type', 'application/json');\n      res.send(result);\n      profile.delete();\n    });\n  }, 10000); // 10 second profile\n});", "example": "Find CPU bottlenecks"},
    {"id": "obs15", "type": "profiling", "name": "Memory Profiling", "description": "Detect memory leaks", "pattern": "const v8 = require('v8');\nconst heapdump = require('heapdump');\n\napp.get('/debug/heap', (req, res) => {\n  const filename = `/tmp/heap-${Date.now()}.heapsnapshot`;\n  heapdump.writeSnapshot(filename, (err) => {\n    if (err) return res.status(500).json({ error: err.message });\n    res.json({ file: filename, stats: v8.getHeapStatistics() });\n  });\n});", "example": "Heap snapshots for memory analysis"},
    {"id": "obs16", "type": "slo", "name": "SLO Definition", "description": "Define Service Level Objectives", "pattern": "# SLO: 99.9% availability\n# Error budget: 0.1% = 43.2 minutes/month\n\n# Prometheus recording rule\n- record: slo:availability:ratio\n  expr: |\n    1 - (\n      sum(rate(http_requests_total{status=~\"5..\"}[30d]))\n      / sum(rate(http_requests_total[30d]))\n    )\n\n# Alert when burning error budget too fast\n- alert: ErrorBudgetBurn\n  expr: slo:availability:ratio < 0.999", "example": "Track SLO compliance"},
    {"id": "obs17", "type": "metrics", "name": "Business Metrics", "description": "Track business KPIs", "pattern": "const ordersPlaced = new Counter({\n  name: 'orders_placed_total',\n  help: 'Total orders placed',\n  labelNames: ['product_category', 'payment_method']\n});\n\nconst orderValue = new Histogram({\n  name: 'order_value_dollars',\n  help: 'Order value distribution',\n  buckets: [10, 50, 100, 500, 1000]\n});\n\nconst activeUsers = new Gauge({\n  name: 'active_users_current',\n  help: 'Currently active users'\n});", "example": "Connect tech to business outcomes"},
    {"id": "obs18", "type": "synthetic", "name": "Synthetic Monitoring", "description": "Proactive endpoint testing", "pattern": "// Datadog Synthetics or custom\nconst syntheticCheck = async () => {\n  const start = Date.now();\n  try {\n    const res = await fetch('https://api.myapp.com/health');\n    const duration = Date.now() - start;\n    syntheticLatency.observe(duration / 1000);\n    syntheticSuccess.inc();\n  } catch (error) {\n    syntheticFailure.inc();\n    alertOnCall('Synthetic check failed', error);\n  }\n};\nsetInterval(syntheticCheck, 60000);", "example": "Detect issues before users"},
    {"id": "obs19", "type": "rum", "name": "Real User Monitoring", "description": "Track frontend performance", "pattern": "// Browser SDK\nconst rum = new DatadogRum({\n  applicationId: 'xxx',\n  clientToken: 'yyy',\n  site: 'datadoghq.com',\n  service: 'my-frontend',\n  trackInteractions: true,\n  trackResources: true,\n  trackLongTasks: true\n});\n\n// Custom actions\nrum.addAction('checkout_started', { cart_value: 99.99 });", "example": "Track actual user experience"},
    {"id": "obs20", "type": "events", "name": "Event Tracking", "description": "Record deployment and incident events", "pattern": "// Record deployment\nawait fetch('https://api.datadoghq.com/api/v1/events', {\n  method: 'POST',\n  headers: { 'DD-API-KEY': API_KEY },\n  body: JSON.stringify({\n    title: 'Deployment: user-service v1.2.3',\n    text: 'Deployed by CI/CD',\n    tags: ['service:user-service', 'version:1.2.3'],\n    alert_type: 'info'\n  })\n});", "example": "Correlate events with metrics"},
    {"id": "obs21", "type": "sampling", "name": "Trace Sampling", "description": "Control trace volume", "pattern": "// Head-based sampling\nconst sampler = new ParentBasedSampler({\n  root: new TraceIdRatioBasedSampler(0.1) // 10% sampling\n});\n\n// Tail-based sampling (in collector)\nprocessors:\n  tail_sampling:\n    policies:\n      - name: errors\n        type: status_code\n        status_code: { status_codes: [ERROR] }\n      - name: slow\n        type: latency\n        latency: { threshold_ms: 1000 }", "example": "Sample errors and slow requests"},
    {"id": "obs22", "type": "cardinality", "name": "Metric Cardinality", "description": "Manage metric label explosion", "pattern": "// BAD: High cardinality\nconst requests = new Counter({\n  name: 'http_requests',\n  labelNames: ['userId', 'sessionId'] // Millions of combinations!\n});\n\n// GOOD: Bounded cardinality\nconst requests = new Counter({\n  name: 'http_requests',\n  labelNames: ['method', 'path', 'status'] // Finite combinations\n});\n\n// Aggregate user-specific data differently\nuserMetrics.set(userId, { count: 1 }); // Store in DB, not metrics", "example": "Avoid label explosion"},
    {"id": "obs23", "type": "cost", "name": "Observability Cost Control", "description": "Manage data volume and costs", "pattern": "// Log sampling for high-volume paths\nconst shouldLog = (req) => {\n  if (req.path === '/health') return Math.random() < 0.01; // 1%\n  if (req.path.startsWith('/api')) return true;\n  return Math.random() < 0.1; // 10%\n};\n\n// Metric aggregation\nconst aggregator = new MetricAggregator({\n  flushInterval: 60000, // Aggregate locally, send every minute\n  maxBatchSize: 1000\n});", "example": "Balance observability with cost"},
    {"id": "obs24", "type": "correlation", "name": "Logs-Metrics-Traces Correlation", "description": "Connect the three pillars", "pattern": "// Add trace context to logs\nlogger.info({\n  message: 'Processing order',\n  orderId: order.id,\n  traceId: span.spanContext().traceId,\n  spanId: span.spanContext().spanId\n});\n\n// Add trace exemplars to metrics\nrequestDuration.observe(\n  { le: duration },\n  1,\n  { traceID: span.spanContext().traceId }\n);", "example": "Jump between logs, metrics, traces"},
    {"id": "obs25", "type": "oncall", "name": "On-Call Management", "description": "Incident response setup", "pattern": "# PagerDuty schedule\n- team: backend-team\n  schedule:\n    - weekday:\n        primary: alice\n        secondary: bob\n    - weekend:\n        primary: charlie\n        secondary: alice\n  escalation:\n    - wait: 5m\n      notify: primary\n    - wait: 10m\n      notify: secondary\n    - wait: 15m\n      notify: manager", "example": "Rotation and escalation policies"},
    {"id": "obs26", "type": "runbooks", "name": "Runbook Automation", "description": "Automated incident response", "pattern": "// Alert with runbook link\nannotations:\n  runbook_url: https://wiki.company.com/runbooks/high-error-rate\n  \n// Automated remediation\nonAlert('HighMemoryUsage', async (alert) => {\n  if (alert.labels.service === 'cache-service') {\n    await kubectl.rolloutRestart('deployment/cache-service');\n    await slack.notify('#incidents', 'Auto-restarted cache-service due to high memory');\n  }\n});", "example": "Auto-remediation for known issues"},
    {"id": "obs27", "type": "chaos", "name": "Chaos Engineering", "description": "Test system resilience", "pattern": "// Chaos Monkey - random pod termination\napiVersion: chaos-mesh.org/v1alpha1\nkind: PodChaos\nmetadata:\n  name: pod-failure\nspec:\n  action: pod-kill\n  mode: one\n  selector:\n    namespaces: [production]\n  scheduler:\n    cron: '*/30 * * * *'", "example": "Gremlin, Chaos Mesh, Litmus"},
    {"id": "obs28", "type": "anomaly", "name": "Anomaly Detection", "description": "ML-based alerting", "pattern": "// Dynamic thresholds instead of static\nalert:\n  name: AnomalousLatency\n  expr: |\n    abs(\n      http_request_duration_seconds:rate5m \n      - http_request_duration_seconds:rate5m:avg_over_time_1h\n    ) > 3 * http_request_duration_seconds:rate5m:stddev_over_time_1h", "example": "Detect deviations from normal"},
    {"id": "obs29", "type": "sli", "name": "SLI Implementation", "description": "Measure Service Level Indicators", "pattern": "// Availability SLI\nconst availability = successfulRequests / totalRequests;\n\n// Latency SLI (% under threshold)\nconst latencySli = histogram_quantile(0.95, rate(duration_bucket[5m])) < 0.2;\n\n// Throughput SLI\nconst throughputSli = rate(requests_total[5m]) >= 1000;\n\n// Prometheus SLI recording rules\n- record: sli:latency:p95\n  expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le))", "example": "Quantifiable service quality"},
    {"id": "obs30", "type": "postmortem", "name": "Incident Postmortem", "description": "Blameless post-incident review", "pattern": "# Postmortem Template\n## Incident Summary\n- Duration: 45 minutes\n- Impact: 5% of users affected\n- Severity: P2\n\n## Timeline\n- 14:00 - Alert fired for high error rate\n- 14:05 - On-call acknowledged\n- 14:15 - Root cause identified\n- 14:45 - Fix deployed, verified\n\n## Root Cause\nDatabase connection pool exhausted due to connection leak\n\n## Action Items\n- [ ] Add connection pool metrics\n- [ ] Implement connection timeout\n- [ ] Add runbook for this scenario", "example": "Learn from incidents"}
  ]
}
