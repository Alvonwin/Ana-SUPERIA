{
  "category": "openai-api",
  "version": "1.0.0",
  "generatedBy": "Claude (Opus 4.5)",
  "skills": [
    {"id": "oai01", "type": "basics", "name": "OpenAI API Basics", "description": "AI API platform", "pattern": "GPT models, embeddings, DALL-E, Whisper", "example": "AI services"},
    {"id": "oai02", "type": "install", "name": "Installation", "description": "Setup SDK", "pattern": "npm install openai", "example": "Getting started"},
    {"id": "oai03", "type": "client", "name": "Client Setup", "description": "Initialize client", "pattern": "new OpenAI({ apiKey: process.env.OPENAI_API_KEY })", "example": "Client init"},
    {"id": "oai04", "type": "chat", "name": "Chat Completions", "description": "Chat API", "pattern": "openai.chat.completions.create({ model, messages })", "example": "Chat endpoint"},
    {"id": "oai05", "type": "messages", "name": "Message Format", "description": "Chat messages", "pattern": "[{ role: 'system' | 'user' | 'assistant', content }]", "example": "Message structure"},
    {"id": "oai06", "type": "models", "name": "Models", "description": "Available models", "pattern": "gpt-4o, gpt-4-turbo, gpt-3.5-turbo", "example": "Model selection"},
    {"id": "oai07", "type": "streaming", "name": "Streaming", "description": "Stream responses", "pattern": "stream: true, for await (const chunk of stream)", "example": "Streaming"},
    {"id": "oai08", "type": "functions", "name": "Function Calling", "description": "Tool use", "pattern": "tools: [{ type: 'function', function: {...} }]", "example": "Functions"},
    {"id": "oai09", "type": "toolcall", "name": "Tool Calls", "description": "Handle tool calls", "pattern": "choice.message.tool_calls, tool_call_id", "example": "Tool handling"},
    {"id": "oai10", "type": "json", "name": "JSON Mode", "description": "JSON output", "pattern": "response_format: { type: 'json_object' }", "example": "Structured output"},
    {"id": "oai11", "type": "vision", "name": "Vision", "description": "Image input", "pattern": "{ type: 'image_url', image_url: { url } }", "example": "Image analysis"},
    {"id": "oai12", "type": "embeddings", "name": "Embeddings", "description": "Text embeddings", "pattern": "openai.embeddings.create({ model, input })", "example": "Vector embeddings"},
    {"id": "oai13", "type": "dalle", "name": "DALL-E", "description": "Image generation", "pattern": "openai.images.generate({ model: 'dall-e-3', prompt })", "example": "Image gen"},
    {"id": "oai14", "type": "whisper", "name": "Whisper", "description": "Speech-to-text", "pattern": "openai.audio.transcriptions.create({ model: 'whisper-1', file })", "example": "Transcription"},
    {"id": "oai15", "type": "tts", "name": "Text-to-Speech", "description": "Audio generation", "pattern": "openai.audio.speech.create({ model: 'tts-1', voice, input })", "example": "Speech synthesis"},
    {"id": "oai16", "type": "assistants", "name": "Assistants API", "description": "Stateful AI", "pattern": "openai.beta.assistants.create(), threads, runs", "example": "Assistants"},
    {"id": "oai17", "type": "threads", "name": "Threads", "description": "Conversation threads", "pattern": "openai.beta.threads.create(), messages.create()", "example": "Thread management"},
    {"id": "oai18", "type": "runs", "name": "Runs", "description": "Execute assistant", "pattern": "openai.beta.threads.runs.create()", "example": "Run execution"},
    {"id": "oai19", "type": "files", "name": "Files", "description": "File uploads", "pattern": "openai.files.create({ file, purpose })", "example": "File handling"},
    {"id": "oai20", "type": "retrieval", "name": "File Search", "description": "RAG retrieval", "pattern": "tools: [{ type: 'file_search' }]", "example": "Document QA"},
    {"id": "oai21", "type": "codeinterp", "name": "Code Interpreter", "description": "Code execution", "pattern": "tools: [{ type: 'code_interpreter' }]", "example": "Code running"},
    {"id": "oai22", "type": "moderation", "name": "Moderation", "description": "Content moderation", "pattern": "openai.moderations.create({ input })", "example": "Safety"},
    {"id": "oai23", "type": "finetune", "name": "Fine-tuning", "description": "Custom models", "pattern": "openai.fineTuning.jobs.create({ model, training_file })", "example": "Model training"},
    {"id": "oai24", "type": "batch", "name": "Batch API", "description": "Bulk requests", "pattern": "openai.batches.create({ input_file_id })", "example": "Batch processing"},
    {"id": "oai25", "type": "errors", "name": "Error Handling", "description": "API errors", "pattern": "try/catch, APIError, RateLimitError", "example": "Error handling"},
    {"id": "oai26", "type": "ratelimit", "name": "Rate Limits", "description": "Request limits", "pattern": "Retry with exponential backoff", "example": "Rate limiting"},
    {"id": "oai27", "type": "tokens", "name": "Token Counting", "description": "Usage tracking", "pattern": "tiktoken, response.usage.total_tokens", "example": "Token management"},
    {"id": "oai28", "type": "cost", "name": "Cost Management", "description": "Budget control", "pattern": "max_tokens, usage limits, billing", "example": "Cost control"},
    {"id": "oai29", "type": "typescript", "name": "TypeScript", "description": "Type definitions", "pattern": "ChatCompletionMessageParam, full type support", "example": "Type safety"},
    {"id": "oai30", "type": "best", "name": "Best Practices", "description": "OpenAI guidelines", "pattern": "Prompt engineering, error handling, streaming", "example": "Standards"}
  ]
}
