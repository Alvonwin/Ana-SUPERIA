{
  "category": "llm-fine-tuning",
  "version": "1.0.0",
  "generatedBy": "Claude (Opus 4.5)",
  "description": "LLM Fine-Tuning and Customization",
  "skills": [
    {"id": "lft01", "type": "basics", "name": "Fine-Tuning Basics", "description": "Adapt pre-trained models", "pattern": "Base model → Custom model", "example": "Domain adaptation"},
    {"id": "lft02", "type": "basics", "name": "Transfer Learning", "description": "Reuse learned features", "pattern": "Pre-train → Fine-tune", "example": "LLM foundation"},
    {"id": "lft03", "type": "basics", "name": "Instruction Tuning", "description": "Follow instructions", "pattern": "Prompt-response pairs", "example": "ChatGPT-like"},
    {"id": "lft04", "type": "data", "name": "Training Data Preparation", "description": "Quality datasets", "pattern": "Clean, diverse, representative", "example": "Dataset curation"},
    {"id": "lft05", "type": "data", "name": "Data Formatting", "description": "Input format", "pattern": "Prompt templates", "example": "ChatML, Alpaca"},
    {"id": "lft06", "type": "data", "name": "Synthetic Data", "description": "Generated training data", "pattern": "Self-instruct, Evol-Instruct", "example": "Data augmentation"},
    {"id": "lft07", "type": "data", "name": "Data Quality Filtering", "description": "Remove bad examples", "pattern": "Deduplication, toxicity filter", "example": "Clean datasets"},
    {"id": "lft08", "type": "peft", "name": "LoRA", "description": "Low-Rank Adaptation", "pattern": "Trainable rank-decomposition", "example": "Efficient fine-tuning"},
    {"id": "lft09", "type": "peft", "name": "QLoRA", "description": "Quantized LoRA", "pattern": "4-bit + LoRA", "example": "Consumer GPUs"},
    {"id": "lft10", "type": "peft", "name": "Prefix Tuning", "description": "Learnable prefixes", "pattern": "Soft prompts", "example": "Parameter efficient"},
    {"id": "lft11", "type": "peft", "name": "Adapter Layers", "description": "Small trainable layers", "pattern": "Bottleneck adapters", "example": "Modular fine-tuning"},
    {"id": "lft12", "type": "full", "name": "Full Fine-Tuning", "description": "All parameters", "pattern": "Complete model training", "example": "Maximum adaptation"},
    {"id": "lft13", "type": "full", "name": "Catastrophic Forgetting", "description": "Losing old knowledge", "pattern": "Careful learning rates", "example": "Balance old/new"},
    {"id": "lft14", "type": "alignment", "name": "RLHF", "description": "Human feedback", "pattern": "Reward model + PPO", "example": "ChatGPT training"},
    {"id": "lft15", "type": "alignment", "name": "DPO", "description": "Direct Preference Optimization", "pattern": "No reward model needed", "example": "Simpler alignment"},
    {"id": "lft16", "type": "alignment", "name": "ORPO", "description": "Odds Ratio Preference", "pattern": "SFT + preference", "example": "Combined training"},
    {"id": "lft17", "type": "alignment", "name": "Constitutional AI", "description": "Self-critique", "pattern": "Principles-based", "example": "Claude training"},
    {"id": "lft18", "type": "training", "name": "Learning Rate Schedule", "description": "LR over time", "pattern": "Warmup + decay", "example": "Training dynamics"},
    {"id": "lft19", "type": "training", "name": "Gradient Accumulation", "description": "Effective batch size", "pattern": "Accumulate gradients", "example": "Limited memory"},
    {"id": "lft20", "type": "training", "name": "Mixed Precision", "description": "FP16/BF16 training", "pattern": "Faster training", "example": "GPU efficiency"},
    {"id": "lft21", "type": "training", "name": "Gradient Checkpointing", "description": "Memory optimization", "pattern": "Recompute activations", "example": "Large models"},
    {"id": "lft22", "type": "distributed", "name": "DeepSpeed", "description": "Distributed training", "pattern": "ZeRO optimization", "example": "Multi-GPU"},
    {"id": "lft23", "type": "distributed", "name": "FSDP", "description": "Fully Sharded", "pattern": "Model parallelism", "example": "PyTorch native"},
    {"id": "lft24", "type": "evaluation", "name": "Perplexity", "description": "Model quality", "pattern": "Cross-entropy loss", "example": "Language modeling"},
    {"id": "lft25", "type": "evaluation", "name": "Benchmark Evaluation", "description": "Standard tests", "pattern": "MMLU, GSM8K, HumanEval", "example": "Compare models"},
    {"id": "lft26", "type": "tools", "name": "Hugging Face TRL", "description": "Training library", "pattern": "SFT, RLHF support", "example": "Fine-tuning framework"},
    {"id": "lft27", "type": "tools", "name": "Axolotl", "description": "Fine-tuning toolkit", "pattern": "YAML config", "example": "Easy fine-tuning"},
    {"id": "lft28", "type": "tools", "name": "LLaMA-Factory", "description": "All-in-one", "pattern": "GUI + CLI", "example": "User-friendly"},
    {"id": "lft29", "type": "tools", "name": "Weights & Biases", "description": "Experiment tracking", "pattern": "Metrics logging", "example": "Training monitoring"},
    {"id": "lft30", "type": "deployment", "name": "Merging Models", "description": "Combine adapters", "pattern": "TIES, SLERP merge", "example": "Model merging"}
  ]
}
