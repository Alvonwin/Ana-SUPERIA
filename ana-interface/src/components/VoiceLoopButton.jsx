/**
 * VoiceLoopButton - Composant isol√© pour le mode vocal continu
 *
 * Ce composant est s√©par√© pour:
 * 1. Isoler les erreurs potentielles de Web Speech API
 * 2. √âviter de crasher toute la page ChatPage
 * 3. Meilleure maintenance et testabilit√©
 *
 * Source: https://github.com/JamesBrill/react-speech-recognition
 */

import { useState, useEffect, useRef, useCallback, forwardRef, useImperativeHandle } from 'react';
import { IconMic, IconMicOff } from './Icons';
import { BACKEND_URL } from '../config.js';
import { isSpeaking } from '../utils/ttsService';

// Correction orthographique via backend (Anna -> Ana, majuscule, point)
async function correctSpelling(text) {
  try {
    const response = await fetch(`${BACKEND_URL}/api/spellcheck`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text })
    });
    const data = await response.json();
    if (data.success && data.corrected) {
      if (data.changed) {
        console.log('Correction ortho:', text, '->', data.corrected);
      }
      return data.corrected;
    }
  } catch (e) {
    console.warn('Spell check failed:', e.message);
  }
  return text;
}

// V√©rification initiale du support
const SpeechRecognitionAPI = typeof window !== 'undefined'
  ? (window.SpeechRecognition || window.webkitSpeechRecognition)
  : null;

// D√©tection mobile pour ajustements sp√©cifiques
const isMobile = typeof window !== 'undefined' &&
  /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);

const VoiceLoopButton = forwardRef(function VoiceLoopButton({
  onTranscript,
  onListeningChange,
  disabled = false,
  soundSystem = null
}, ref) {
  const [isEnabled, setIsEnabled] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [error, setError] = useState(null);
  const recognitionRef = useRef(null);
  const isEnabledRef = useRef(false);
  const isPausedRef = useRef(false);
  const lastTranscriptRef = useRef('');  // Mobile: anti-doublon
  const lastTranscriptTimeRef = useRef(0);  // Mobile: debounce

  // Sync ref with state
  useEffect(() => {
    isEnabledRef.current = isEnabled;
  }, [isEnabled]);

  // Expose pause/resume au parent pour coordination TTS
  useImperativeHandle(ref, () => ({
    pause: () => {
      console.log('‚è∏Ô∏è VoiceLoop: pause demand√© par parent');
      isPausedRef.current = true;
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
        } catch (e) {
          console.warn('‚ö†Ô∏è Pause error:', e.message);
        }
      }
    },
    resume: () => {
      console.log('‚ñ∂Ô∏è VoiceLoop: resume demand√© par parent');
      isPausedRef.current = false;
      if (isEnabledRef.current && recognitionRef.current) {
        try {
          recognitionRef.current.start();
        } catch (e) {
          console.warn('‚ö†Ô∏è Resume error:', e.message);
        }
      }
    }
  }));

  // Notify parent of listening state changes
  useEffect(() => {
    if (onListeningChange) {
      onListeningChange(isListening);
    }
  }, [isListening, onListeningChange]);

  // Initialize SpeechRecognition
  const initRecognition = useCallback(() => {
    if (!SpeechRecognitionAPI) {
      setError('Speech Recognition non support√©');
      return null;
    }

    try {
      const recognition = new SpeechRecognitionAPI();
      recognition.lang = 'fr-CA' // Canadian French - plus tolerant aux mots anglais;
      recognition.continuous = true;
      // Mobile: d√©sactiver interimResults pour √©viter les doublons
      recognition.interimResults = !isMobile;

      recognition.onstart = () => {
        console.log('üé§ √âcoute d√©marr√©e');
        setIsListening(true);
        setError(null);
      };

      recognition.onend = () => {
        console.log('üé§ √âcoute termin√©e');

        // FIX 2025-12-21: Ne pas mettre isListening √† false si on va red√©marrer
        // Cela √©vite le "flash" du bouton pendant le cycle de red√©marrage
        if (isEnabledRef.current && !isPausedRef.current) {
          // Red√©marrer automatiquement - garder l'indicateur actif
          const restartDelay = isMobile ? 1500 : 300;
          console.log(`üîÑ Red√©marrage automatique dans ${restartDelay}ms...`);
          setTimeout(() => {
            if (isEnabledRef.current && recognitionRef.current && !isPausedRef.current) {
              try {
                recognitionRef.current.start();
              } catch (e) {
                console.warn('‚ö†Ô∏è Impossible de red√©marrer:', e.message);
                setIsListening(false);  // Seulement si √©chec
              }
            } else {
              setIsListening(false);  // Mode d√©sactiv√© entre-temps
            }
          }, restartDelay);
        } else {
          // Mode d√©sactiv√© ou TTS en cours - vraiment arr√™ter
          setIsListening(false);
          if (isPausedRef.current) {
            console.log('‚è∏Ô∏è Pas de red√©marrage - TTS en cours');
          }
        }
      };

      recognition.onresult = async (event) => {
        // Ignorer les transcriptions si Ana parle (TTS en cours)
        if (isSpeaking()) {
          console.log('üîá Transcription ignor√©e - TTS en cours');
          return;
        }

        let finalTranscript = '';
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript;
          }
        }
        if (finalTranscript && onTranscript) {
          const trimmed = finalTranscript.trim();
          const now = Date.now();

          // Mobile: anti-doublon - ignorer si m√™me texte dans les 2 derni√®res secondes
          if (isMobile) {
            const timeSinceLast = now - lastTranscriptTimeRef.current;
            if (trimmed === lastTranscriptRef.current && timeSinceLast < 2000) {
              console.log('üö´ Mobile: doublon ignor√©:', trimmed);
              return;
            }
            lastTranscriptRef.current = trimmed;
            lastTranscriptTimeRef.current = now;
          }

          // Correction orthographique avant envoi
          const corrected = await correctSpelling(trimmed);
          console.log('üé§ Transcript final (corrig√©):', corrected);
          onTranscript(corrected);
        }
      };

      recognition.onerror = (event) => {
        console.error('‚ùå Erreur Speech Recognition:', event.error);
        if (event.error === 'aborted' || event.error === 'no-speech') {
          return;
        }
        setError();
        setIsListening(false);
      };

      return recognition;
    } catch (e) {
      console.error('‚ùå Erreur cr√©ation SpeechRecognition:', e);
      setError("Impossible d'initialiser la reconnaissance vocale");
      return null;
    }
  }, [onTranscript]);

  // Toggle voice mode
  const toggleVoiceMode = useCallback(() => {
    try {
      if (!isEnabled) {
        if (!recognitionRef.current) {
          recognitionRef.current = initRecognition();
        }
        if (recognitionRef.current) {
          setIsEnabled(true);
          isPausedRef.current = false;
          if (soundSystem) soundSystem.play('success');
          try {
            recognitionRef.current.start();
          } catch (e) {
            if (!e.message.includes('already started')) throw e;
          }
        }
      } else {
        setIsEnabled(false);
        if (soundSystem) soundSystem.play('llm-complete');
        if (recognitionRef.current) {
          try { recognitionRef.current.stop(); } catch (e) {}
        }
        setIsListening(false);
      }
    } catch (e) {
      console.error('‚ùå Erreur toggle voice mode:', e);
      setError(e.message);
      setIsEnabled(false);
      setIsListening(false);
    }
  }, [isEnabled, initRecognition, soundSystem]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        try { recognitionRef.current.stop(); } catch (e) {}
      }
    };
  }, []);

  if (!SpeechRecognitionAPI) return null;

  return (
    <button
      className={`voice-loop-btn ${isEnabled ? "active" : ""}`}
      onClick={toggleVoiceMode}
      disabled={disabled}
      title={error || (isEnabled ? 'D√©sactiver le mode vocal' : 'Activer le mode vocal continu')}
    >
      {isEnabled ? <IconMic size={16} /> : <IconMicOff size={16} />}
      <span>Mode Vocal {isEnabled ? 'ON' : 'OFF'}</span>
      {isListening && <span className="listening-indicator">‚óè</span>}
    </button>
  );
});

export default VoiceLoopButton;
