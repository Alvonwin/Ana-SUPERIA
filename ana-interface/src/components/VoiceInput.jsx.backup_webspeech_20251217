import { useState, useRef } from 'react';
import './VoiceInput.css';
import { BACKEND_URL } from '../config.js';

// Correction orthographique via backend (Anna -> Ana, etc.)
async function correctSpelling(text) {
  try {
    const response = await fetch(`${BACKEND_URL}/api/spellcheck`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text })
    });
    const data = await response.json();
    if (data.success && data.corrected) {
      if (data.changed) {
        console.log('Correction:', text, '->', data.corrected);
      }
      return data.corrected;
    }
  } catch (e) {
    console.warn('Spell check failed:', e.message);
  }
  return text;
}

function VoiceInput({ onTranscript, onAutoSubmit, disabled = false }) {
  const [isRecording, setIsRecording] = useState(false);
  const [status, setStatus] = useState('Pr√™t');
  const recognitionRef = useRef(null);

  const startRecording = () => {
    if (disabled) {
      setStatus('Entr√©e vocale d√©sactiv√©e');
      return;
    }

    // V√©rifier support navigateur
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (!SpeechRecognition) {
      setStatus('‚ùå Speech Recognition non support√©');
      return;
    }

    try {
      const recognition = new SpeechRecognition();
      recognition.lang = 'fr-CA' // Canadian French - plus tolerant aux mots anglais;
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.maxAlternatives = 1;

      recognition.onstart = () => {
        setIsRecording(true);
        setStatus('üé§ √âcoute en cours...');
        console.log('üé§ Enregistrement d√©marr√©');
      };

      recognition.onresult = async (event) => {
        const rawTranscript = event.results[0][0].transcript;
        const transcript = await correctSpelling(rawTranscript);
        console.log('üìù Transcription:', transcript);

        if (onTranscript) {
          onTranscript(transcript);
        }

        setStatus('‚úÖ Transcription compl√®te');

        // Auto-submit apr√®s transcription avec le transcript en param√®tre direct
        if (onAutoSubmit) {
          console.log('üöÄ Auto-submit d√©clench√© avec:', transcript);
          setTimeout(() => {
            onAutoSubmit(transcript);
          }, 200);
        }
      };

      recognition.onerror = (event) => {
        console.error('‚ùå Erreur reconnaissance vocale:', event.error);
        setStatus(`‚ùå Erreur: ${event.error}`);
        setIsRecording(false);
      };

      recognition.onend = () => {
        setIsRecording(false);
        setStatus('Pr√™t');
        console.log('‚èπÔ∏è Enregistrement termin√©');
      };

      recognitionRef.current = recognition;
      recognition.start();

    } catch (error) {
      console.error('‚ùå Erreur d√©marrage:', error);
      setStatus('‚ùå Erreur d√©marrage');
      setIsRecording(false);
    }
  };

  const stopRecording = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
  };

  const handleClick = () => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  return (
    <div className="voice-input">
      <button
        className={`voice-btn ${isRecording ? 'recording' : ''} ${disabled ? 'disabled' : ''}`}
        onClick={handleClick}
        disabled={disabled}
        title={status}
      >
        {isRecording ? (
          <span style={{ fontSize: '20px' }}>‚èπÔ∏è</span>
        ) : (
          <span style={{ fontSize: '20px' }}>üé§</span>
        )}
      </button>
      {isRecording && (
        <div className="voice-status">
          <span className="pulse-dot"></span>
          {status}
        </div>
      )}
    </div>
  );
}

export default VoiceInput;
